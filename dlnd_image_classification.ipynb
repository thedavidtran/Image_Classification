{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 50:\n",
      "Image - Min Value: 5 Max Value: 254\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 3 Name: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNCboAaCx/wupbxTPlCKLogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bbed486b00>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 50\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # RGB channels\n",
    "    # 8-bit color graphics is adopt to store image files in this dataset so that each pixel is represented by one 8-bit byte. 2^8 = 256\n",
    "    return np.array(x / 255)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    lb.fit(x)\n",
    "    lb.classes_ = np.array(list(range(10)))\n",
    "    return lb.transform(x)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # image_shape is a tuple (x, y, pixel_depth)\n",
    "    return tf.placeholder(tf.float32, shape=[None, *image_shape], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    input_channel_depth = int(x_tensor.get_shape()[3])\n",
    "\n",
    "    conv_ksize_height = conv_ksize[0]\n",
    "    conv_ksize_width = conv_ksize[1]\n",
    "    conv_stride_height = conv_strides[0]\n",
    "    conv_stride_width = conv_strides[1]\n",
    "    \n",
    "    pool_ksize_height = pool_ksize[0]\n",
    "    pool_ksize_width = pool_ksize[1]\n",
    "    pool_stride_height = pool_strides[0]\n",
    "    pool_stride_width = pool_strides[1]\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([conv_ksize_height, conv_ksize_width, input_channel_depth, conv_num_outputs], mean=0.0, stddev=0.05, dtype=tf.float32))\n",
    "    biases = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=x_tensor, filter=weights, strides=[1, conv_stride_height, conv_stride_width, 1], padding='SAME')\n",
    "    layer = tf.nn.bias_add(layer, biases)\n",
    "    layer = tf.nn.max_pool(layer, [1, pool_ksize_height, pool_ksize_width, 1], strides=[1, pool_stride_height, pool_stride_width, 1], padding='SAME')\n",
    "    return layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # (batch_size, height, width, depth) => (batch_size, flattened_image_size)\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    batch_size = shape[0] or -1\n",
    "    height = shape[1]\n",
    "    width = shape[2]\n",
    "    depth = shape[3]\n",
    "    flattened_image_size = height * width * depth\n",
    "\n",
    "    return tf.reshape(x_tensor, [batch_size, flattened_image_size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    batch_size = x_tensor.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal((batch_size, num_outputs), mean=0.0, stddev=0.01))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "    fully_conn_layer = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    \n",
    "    return fully_conn_layer\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    batch_size = x_tensor.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal((batch_size, num_outputs), mean=0.0, stddev=0.01, dtype=tf.float32, seed=None))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    output_layer = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    return output_layer\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_num_outputs1 = 32\n",
    "    conv_num_outputs2 = 64\n",
    "    conv_ksize = (4, 4)\n",
    "    conv_strides = (2, 2)\n",
    "    pool_ksize = (3, 3)\n",
    "    pool_strides = (2, 2)\n",
    "    num_outputs = 10\n",
    "    \n",
    "    cnn = conv2d_maxpool(x, conv_num_outputs1, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    cnn = conv2d_maxpool(cnn, conv_num_outputs2, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    cnn = flatten(cnn)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    cnn = fully_conn(cnn, 128)\n",
    "    cnn = fully_conn(cnn, 64)\n",
    "    cnn = tf.nn.dropout(cnn, 0.7)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    output_layer = output(cnn, num_outputs)\n",
    "    return output_layer\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch})\n",
    "    print('Acc: {} Loss: {}'.format(acc, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 512\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Acc: 0.1754000037908554 Loss: 2.2413489818573\n",
      "Epoch  2, CIFAR-10 Batch 1:  Acc: 0.23739998042583466 Loss: 2.0268983840942383\n",
      "Epoch  3, CIFAR-10 Batch 1:  Acc: 0.27619996666908264 Loss: 1.966383457183838\n",
      "Epoch  4, CIFAR-10 Batch 1:  Acc: 0.2919999957084656 Loss: 1.904874324798584\n",
      "Epoch  5, CIFAR-10 Batch 1:  Acc: 0.2937999963760376 Loss: 1.8732104301452637\n",
      "Epoch  6, CIFAR-10 Batch 1:  Acc: 0.3007999658584595 Loss: 1.8467795848846436\n",
      "Epoch  7, CIFAR-10 Batch 1:  Acc: 0.3149999976158142 Loss: 1.790547251701355\n",
      "Epoch  8, CIFAR-10 Batch 1:  Acc: 0.32440000772476196 Loss: 1.7809481620788574\n",
      "Epoch  9, CIFAR-10 Batch 1:  Acc: 0.3577999770641327 Loss: 1.7556349039077759\n",
      "Epoch 10, CIFAR-10 Batch 1:  Acc: 0.37019994854927063 Loss: 1.7416496276855469\n",
      "Epoch 11, CIFAR-10 Batch 1:  Acc: 0.39299994707107544 Loss: 1.6860543489456177\n",
      "Epoch 12, CIFAR-10 Batch 1:  Acc: 0.3997999429702759 Loss: 1.6629055738449097\n",
      "Epoch 13, CIFAR-10 Batch 1:  Acc: 0.40539997816085815 Loss: 1.6247371435165405\n",
      "Epoch 14, CIFAR-10 Batch 1:  Acc: 0.423799991607666 Loss: 1.5634939670562744\n",
      "Epoch 15, CIFAR-10 Batch 1:  Acc: 0.42559993267059326 Loss: 1.5518394708633423\n",
      "Epoch 16, CIFAR-10 Batch 1:  Acc: 0.4355999827384949 Loss: 1.5017096996307373\n",
      "Epoch 17, CIFAR-10 Batch 1:  Acc: 0.4349999725818634 Loss: 1.4853678941726685\n",
      "Epoch 18, CIFAR-10 Batch 1:  Acc: 0.44120001792907715 Loss: 1.4663102626800537\n",
      "Epoch 19, CIFAR-10 Batch 1:  Acc: 0.44599997997283936 Loss: 1.4331754446029663\n",
      "Epoch 20, CIFAR-10 Batch 1:  Acc: 0.454399973154068 Loss: 1.418091893196106\n",
      "Epoch 21, CIFAR-10 Batch 1:  Acc: 0.4607999622821808 Loss: 1.3911625146865845\n",
      "Epoch 22, CIFAR-10 Batch 1:  Acc: 0.45259997248649597 Loss: 1.3827109336853027\n",
      "Epoch 23, CIFAR-10 Batch 1:  Acc: 0.4575999677181244 Loss: 1.3563863039016724\n",
      "Epoch 24, CIFAR-10 Batch 1:  Acc: 0.4667999744415283 Loss: 1.340725064277649\n",
      "Epoch 25, CIFAR-10 Batch 1:  Acc: 0.4607999622821808 Loss: 1.3176575899124146\n",
      "Epoch 26, CIFAR-10 Batch 1:  Acc: 0.47359997034072876 Loss: 1.276315450668335\n",
      "Epoch 27, CIFAR-10 Batch 1:  Acc: 0.475600004196167 Loss: 1.241912603378296\n",
      "Epoch 28, CIFAR-10 Batch 1:  Acc: 0.47499996423721313 Loss: 1.2128236293792725\n",
      "Epoch 29, CIFAR-10 Batch 1:  Acc: 0.4869999885559082 Loss: 1.1872822046279907\n",
      "Epoch 30, CIFAR-10 Batch 1:  Acc: 0.4875999689102173 Loss: 1.158917784690857\n",
      "Epoch 31, CIFAR-10 Batch 1:  Acc: 0.49219998717308044 Loss: 1.1264621019363403\n",
      "Epoch 32, CIFAR-10 Batch 1:  Acc: 0.4893999397754669 Loss: 1.0895581245422363\n",
      "Epoch 33, CIFAR-10 Batch 1:  Acc: 0.49039995670318604 Loss: 1.079898476600647\n",
      "Epoch 34, CIFAR-10 Batch 1:  Acc: 0.49439993500709534 Loss: 1.0457422733306885\n",
      "Epoch 35, CIFAR-10 Batch 1:  Acc: 0.49379995465278625 Loss: 1.028113842010498\n",
      "Epoch 36, CIFAR-10 Batch 1:  Acc: 0.49299997091293335 Loss: 0.9860177040100098\n",
      "Epoch 37, CIFAR-10 Batch 1:  Acc: 0.4995999336242676 Loss: 0.9892438054084778\n",
      "Epoch 38, CIFAR-10 Batch 1:  Acc: 0.4975999593734741 Loss: 0.9455861449241638\n",
      "Epoch 39, CIFAR-10 Batch 1:  Acc: 0.503600001335144 Loss: 0.9217743873596191\n",
      "Epoch 40, CIFAR-10 Batch 1:  Acc: 0.5043999552726746 Loss: 0.9421759247779846\n",
      "Epoch 41, CIFAR-10 Batch 1:  Acc: 0.5091999769210815 Loss: 0.8831068277359009\n",
      "Epoch 42, CIFAR-10 Batch 1:  Acc: 0.5033999681472778 Loss: 0.8783636093139648\n",
      "Epoch 43, CIFAR-10 Batch 1:  Acc: 0.5023999214172363 Loss: 0.8966637849807739\n",
      "Epoch 44, CIFAR-10 Batch 1:  Acc: 0.5087999701499939 Loss: 0.8343760371208191\n",
      "Epoch 45, CIFAR-10 Batch 1:  Acc: 0.5125999450683594 Loss: 0.8265141248703003\n",
      "Epoch 46, CIFAR-10 Batch 1:  Acc: 0.520599901676178 Loss: 0.7661092877388\n",
      "Epoch 47, CIFAR-10 Batch 1:  Acc: 0.5121999382972717 Loss: 0.7782468795776367\n",
      "Epoch 48, CIFAR-10 Batch 1:  Acc: 0.4981999397277832 Loss: 0.7942917346954346\n",
      "Epoch 49, CIFAR-10 Batch 1:  Acc: 0.5095999836921692 Loss: 0.766413688659668\n",
      "Epoch 50, CIFAR-10 Batch 1:  Acc: 0.5219998955726624 Loss: 0.7027196884155273\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Acc: 0.17880000174045563 Loss: 2.226203680038452\n",
      "Epoch  1, CIFAR-10 Batch 2:  Acc: 0.2369999885559082 Loss: 1.9336128234863281\n",
      "Epoch  1, CIFAR-10 Batch 3:  Acc: 0.2635999917984009 Loss: 1.882988452911377\n",
      "Epoch  1, CIFAR-10 Batch 4:  Acc: 0.2789999842643738 Loss: 1.8200246095657349\n",
      "Epoch  1, CIFAR-10 Batch 5:  Acc: 0.28119999170303345 Loss: 1.8551321029663086\n",
      "Epoch  2, CIFAR-10 Batch 1:  Acc: 0.29579997062683105 Loss: 1.8465068340301514\n",
      "Epoch  2, CIFAR-10 Batch 2:  Acc: 0.32440000772476196 Loss: 1.758941411972046\n",
      "Epoch  2, CIFAR-10 Batch 3:  Acc: 0.32760000228881836 Loss: 1.659275770187378\n",
      "Epoch  2, CIFAR-10 Batch 4:  Acc: 0.3531999886035919 Loss: 1.6261022090911865\n",
      "Epoch  2, CIFAR-10 Batch 5:  Acc: 0.3659999966621399 Loss: 1.699941873550415\n",
      "Epoch  3, CIFAR-10 Batch 1:  Acc: 0.36799997091293335 Loss: 1.734409213066101\n",
      "Epoch  3, CIFAR-10 Batch 2:  Acc: 0.3905999958515167 Loss: 1.6472129821777344\n",
      "Epoch  3, CIFAR-10 Batch 3:  Acc: 0.3901999890804291 Loss: 1.4562751054763794\n",
      "Epoch  3, CIFAR-10 Batch 4:  Acc: 0.40219998359680176 Loss: 1.5048109292984009\n",
      "Epoch  3, CIFAR-10 Batch 5:  Acc: 0.40939998626708984 Loss: 1.569394826889038\n",
      "Epoch  4, CIFAR-10 Batch 1:  Acc: 0.42139992117881775 Loss: 1.6159868240356445\n",
      "Epoch  4, CIFAR-10 Batch 2:  Acc: 0.43199995160102844 Loss: 1.5170395374298096\n",
      "Epoch  4, CIFAR-10 Batch 3:  Acc: 0.4389999508857727 Loss: 1.3410766124725342\n",
      "Epoch  4, CIFAR-10 Batch 4:  Acc: 0.4273999333381653 Loss: 1.4261730909347534\n",
      "Epoch  4, CIFAR-10 Batch 5:  Acc: 0.45579999685287476 Loss: 1.438948631286621\n",
      "Epoch  5, CIFAR-10 Batch 1:  Acc: 0.4553999602794647 Loss: 1.5073223114013672\n",
      "Epoch  5, CIFAR-10 Batch 2:  Acc: 0.45699992775917053 Loss: 1.4335603713989258\n",
      "Epoch  5, CIFAR-10 Batch 3:  Acc: 0.4691999554634094 Loss: 1.2421586513519287\n",
      "Epoch  5, CIFAR-10 Batch 4:  Acc: 0.4673999547958374 Loss: 1.3124566078186035\n",
      "Epoch  5, CIFAR-10 Batch 5:  Acc: 0.4835999608039856 Loss: 1.3590970039367676\n",
      "Epoch  6, CIFAR-10 Batch 1:  Acc: 0.4817999303340912 Loss: 1.4472954273223877\n",
      "Epoch  6, CIFAR-10 Batch 2:  Acc: 0.4731999635696411 Loss: 1.3956544399261475\n",
      "Epoch  6, CIFAR-10 Batch 3:  Acc: 0.488599956035614 Loss: 1.1740039587020874\n",
      "Epoch  6, CIFAR-10 Batch 4:  Acc: 0.49859994649887085 Loss: 1.2455323934555054\n",
      "Epoch  6, CIFAR-10 Batch 5:  Acc: 0.48799994587898254 Loss: 1.3086960315704346\n",
      "Epoch  7, CIFAR-10 Batch 1:  Acc: 0.5023999214172363 Loss: 1.3916646242141724\n",
      "Epoch  7, CIFAR-10 Batch 2:  Acc: 0.4941999614238739 Loss: 1.3025732040405273\n",
      "Epoch  7, CIFAR-10 Batch 3:  Acc: 0.5023999810218811 Loss: 1.1796083450317383\n",
      "Epoch  7, CIFAR-10 Batch 4:  Acc: 0.5183999538421631 Loss: 1.169694185256958\n",
      "Epoch  7, CIFAR-10 Batch 5:  Acc: 0.511199951171875 Loss: 1.2171558141708374\n",
      "Epoch  8, CIFAR-10 Batch 1:  Acc: 0.5199999213218689 Loss: 1.30997896194458\n",
      "Epoch  8, CIFAR-10 Batch 2:  Acc: 0.5113999247550964 Loss: 1.249916434288025\n",
      "Epoch  8, CIFAR-10 Batch 3:  Acc: 0.5109999179840088 Loss: 1.1192796230316162\n",
      "Epoch  8, CIFAR-10 Batch 4:  Acc: 0.5327999591827393 Loss: 1.1142525672912598\n",
      "Epoch  8, CIFAR-10 Batch 5:  Acc: 0.5295999050140381 Loss: 1.1663789749145508\n",
      "Epoch  9, CIFAR-10 Batch 1:  Acc: 0.5203999280929565 Loss: 1.2861279249191284\n",
      "Epoch  9, CIFAR-10 Batch 2:  Acc: 0.5269999504089355 Loss: 1.192244052886963\n",
      "Epoch  9, CIFAR-10 Batch 3:  Acc: 0.5233999490737915 Loss: 1.0648680925369263\n",
      "Epoch  9, CIFAR-10 Batch 4:  Acc: 0.5421999096870422 Loss: 1.0664069652557373\n",
      "Epoch  9, CIFAR-10 Batch 5:  Acc: 0.5309999585151672 Loss: 1.1361308097839355\n",
      "Epoch 10, CIFAR-10 Batch 1:  Acc: 0.5415999293327332 Loss: 1.2179269790649414\n",
      "Epoch 10, CIFAR-10 Batch 2:  Acc: 0.5247998833656311 Loss: 1.1533620357513428\n",
      "Epoch 10, CIFAR-10 Batch 3:  Acc: 0.5475999116897583 Loss: 1.0325504541397095\n",
      "Epoch 10, CIFAR-10 Batch 4:  Acc: 0.5503999590873718 Loss: 1.0047638416290283\n",
      "Epoch 10, CIFAR-10 Batch 5:  Acc: 0.5369999408721924 Loss: 1.1214035749435425\n",
      "Epoch 11, CIFAR-10 Batch 1:  Acc: 0.5589999556541443 Loss: 1.1494163274765015\n",
      "Epoch 11, CIFAR-10 Batch 2:  Acc: 0.5363999605178833 Loss: 1.0921066999435425\n",
      "Epoch 11, CIFAR-10 Batch 3:  Acc: 0.5481999516487122 Loss: 0.9855891466140747\n",
      "Epoch 11, CIFAR-10 Batch 4:  Acc: 0.5585999488830566 Loss: 0.9682544469833374\n",
      "Epoch 11, CIFAR-10 Batch 5:  Acc: 0.5633999705314636 Loss: 1.048980951309204\n",
      "Epoch 12, CIFAR-10 Batch 1:  Acc: 0.5723998546600342 Loss: 1.0859991312026978\n",
      "Epoch 12, CIFAR-10 Batch 2:  Acc: 0.550399899482727 Loss: 1.0710569620132446\n",
      "Epoch 12, CIFAR-10 Batch 3:  Acc: 0.5595999360084534 Loss: 0.9662208557128906\n",
      "Epoch 12, CIFAR-10 Batch 4:  Acc: 0.5745999217033386 Loss: 0.9187723994255066\n",
      "Epoch 12, CIFAR-10 Batch 5:  Acc: 0.5631998777389526 Loss: 1.0399627685546875\n",
      "Epoch 13, CIFAR-10 Batch 1:  Acc: 0.5757998824119568 Loss: 1.0702497959136963\n",
      "Epoch 13, CIFAR-10 Batch 2:  Acc: 0.555199921131134 Loss: 1.0187644958496094\n",
      "Epoch 13, CIFAR-10 Batch 3:  Acc: 0.5711999535560608 Loss: 0.9115405678749084\n",
      "Epoch 13, CIFAR-10 Batch 4:  Acc: 0.5881999135017395 Loss: 0.8984431028366089\n",
      "Epoch 13, CIFAR-10 Batch 5:  Acc: 0.5747998952865601 Loss: 0.9952119588851929\n",
      "Epoch 14, CIFAR-10 Batch 1:  Acc: 0.5817999243736267 Loss: 1.0068777799606323\n",
      "Epoch 14, CIFAR-10 Batch 2:  Acc: 0.5719999074935913 Loss: 0.9633890986442566\n",
      "Epoch 14, CIFAR-10 Batch 3:  Acc: 0.5771999359130859 Loss: 0.8861043453216553\n",
      "Epoch 14, CIFAR-10 Batch 4:  Acc: 0.5937999486923218 Loss: 0.8586980700492859\n",
      "Epoch 14, CIFAR-10 Batch 5:  Acc: 0.5823999047279358 Loss: 0.950086236000061\n",
      "Epoch 15, CIFAR-10 Batch 1:  Acc: 0.5859999060630798 Loss: 0.9902316927909851\n",
      "Epoch 15, CIFAR-10 Batch 2:  Acc: 0.5817999839782715 Loss: 0.9398336410522461\n",
      "Epoch 15, CIFAR-10 Batch 3:  Acc: 0.5731998682022095 Loss: 0.8543508648872375\n",
      "Epoch 15, CIFAR-10 Batch 4:  Acc: 0.6013998985290527 Loss: 0.8173103928565979\n",
      "Epoch 15, CIFAR-10 Batch 5:  Acc: 0.5865999460220337 Loss: 0.9364800453186035\n",
      "Epoch 16, CIFAR-10 Batch 1:  Acc: 0.5909999012947083 Loss: 0.9676540493965149\n",
      "Epoch 16, CIFAR-10 Batch 2:  Acc: 0.5791999101638794 Loss: 0.9145694375038147\n",
      "Epoch 16, CIFAR-10 Batch 3:  Acc: 0.5853999257087708 Loss: 0.8577209115028381\n",
      "Epoch 16, CIFAR-10 Batch 4:  Acc: 0.6035999655723572 Loss: 0.811599612236023\n",
      "Epoch 16, CIFAR-10 Batch 5:  Acc: 0.6045998930931091 Loss: 0.8981480002403259\n",
      "Epoch 17, CIFAR-10 Batch 1:  Acc: 0.5963999032974243 Loss: 0.9714951515197754\n",
      "Epoch 17, CIFAR-10 Batch 2:  Acc: 0.5913999080657959 Loss: 0.8707564473152161\n",
      "Epoch 17, CIFAR-10 Batch 3:  Acc: 0.5983999371528625 Loss: 0.8338942527770996\n",
      "Epoch 17, CIFAR-10 Batch 4:  Acc: 0.6111999750137329 Loss: 0.795118510723114\n",
      "Epoch 17, CIFAR-10 Batch 5:  Acc: 0.609799861907959 Loss: 0.8398147821426392\n",
      "Epoch 18, CIFAR-10 Batch 1:  Acc: 0.604999840259552 Loss: 0.9262722134590149\n",
      "Epoch 18, CIFAR-10 Batch 2:  Acc: 0.5999999046325684 Loss: 0.842928946018219\n",
      "Epoch 18, CIFAR-10 Batch 3:  Acc: 0.6001998782157898 Loss: 0.7654184103012085\n",
      "Epoch 18, CIFAR-10 Batch 4:  Acc: 0.612799882888794 Loss: 0.7782278060913086\n",
      "Epoch 18, CIFAR-10 Batch 5:  Acc: 0.6079999208450317 Loss: 0.8347100019454956\n",
      "Epoch 19, CIFAR-10 Batch 1:  Acc: 0.6065999269485474 Loss: 0.8739418983459473\n",
      "Epoch 19, CIFAR-10 Batch 2:  Acc: 0.6141998767852783 Loss: 0.8152300715446472\n",
      "Epoch 19, CIFAR-10 Batch 3:  Acc: 0.6117998361587524 Loss: 0.7583877444267273\n",
      "Epoch 19, CIFAR-10 Batch 4:  Acc: 0.605199933052063 Loss: 0.7736740112304688\n",
      "Epoch 19, CIFAR-10 Batch 5:  Acc: 0.6143999099731445 Loss: 0.8072420954704285\n",
      "Epoch 20, CIFAR-10 Batch 1:  Acc: 0.6045998930931091 Loss: 0.8753588199615479\n",
      "Epoch 20, CIFAR-10 Batch 2:  Acc: 0.6155999302864075 Loss: 0.7791430950164795\n",
      "Epoch 20, CIFAR-10 Batch 3:  Acc: 0.6117998957633972 Loss: 0.7486189007759094\n",
      "Epoch 20, CIFAR-10 Batch 4:  Acc: 0.6197999715805054 Loss: 0.7416241765022278\n",
      "Epoch 20, CIFAR-10 Batch 5:  Acc: 0.6151999235153198 Loss: 0.7887402772903442\n",
      "Epoch 21, CIFAR-10 Batch 1:  Acc: 0.6059999465942383 Loss: 0.8748589158058167\n",
      "Epoch 21, CIFAR-10 Batch 2:  Acc: 0.6025999188423157 Loss: 0.7534373998641968\n",
      "Epoch 21, CIFAR-10 Batch 3:  Acc: 0.6177998781204224 Loss: 0.7207498550415039\n",
      "Epoch 21, CIFAR-10 Batch 4:  Acc: 0.6157999038696289 Loss: 0.7091636657714844\n",
      "Epoch 21, CIFAR-10 Batch 5:  Acc: 0.6269999146461487 Loss: 0.7770528793334961\n",
      "Epoch 22, CIFAR-10 Batch 1:  Acc: 0.6077999472618103 Loss: 0.8244185447692871\n",
      "Epoch 22, CIFAR-10 Batch 2:  Acc: 0.6089999079704285 Loss: 0.7399312257766724\n",
      "Epoch 22, CIFAR-10 Batch 3:  Acc: 0.6135998964309692 Loss: 0.6891166567802429\n",
      "Epoch 22, CIFAR-10 Batch 4:  Acc: 0.6235998868942261 Loss: 0.7060480713844299\n",
      "Epoch 22, CIFAR-10 Batch 5:  Acc: 0.6271998882293701 Loss: 0.7367373704910278\n",
      "Epoch 23, CIFAR-10 Batch 1:  Acc: 0.6079999208450317 Loss: 0.8258365392684937\n",
      "Epoch 23, CIFAR-10 Batch 2:  Acc: 0.6097999215126038 Loss: 0.7132145166397095\n",
      "Epoch 23, CIFAR-10 Batch 3:  Acc: 0.6303998827934265 Loss: 0.6714725494384766\n",
      "Epoch 23, CIFAR-10 Batch 4:  Acc: 0.6239999532699585 Loss: 0.6961455941200256\n",
      "Epoch 23, CIFAR-10 Batch 5:  Acc: 0.6289998888969421 Loss: 0.6871570944786072\n",
      "Epoch 24, CIFAR-10 Batch 1:  Acc: 0.6147998571395874 Loss: 0.8125004172325134\n",
      "Epoch 24, CIFAR-10 Batch 2:  Acc: 0.5981998443603516 Loss: 0.7374380230903625\n",
      "Epoch 24, CIFAR-10 Batch 3:  Acc: 0.6143999099731445 Loss: 0.6935302019119263\n",
      "Epoch 24, CIFAR-10 Batch 4:  Acc: 0.6209999322891235 Loss: 0.6672806739807129\n",
      "Epoch 24, CIFAR-10 Batch 5:  Acc: 0.6263999342918396 Loss: 0.711013674736023\n",
      "Epoch 25, CIFAR-10 Batch 1:  Acc: 0.6215999126434326 Loss: 0.7850985527038574\n",
      "Epoch 25, CIFAR-10 Batch 2:  Acc: 0.5863999724388123 Loss: 0.7119114398956299\n",
      "Epoch 25, CIFAR-10 Batch 3:  Acc: 0.6221998929977417 Loss: 0.6460838317871094\n",
      "Epoch 25, CIFAR-10 Batch 4:  Acc: 0.6245999336242676 Loss: 0.6476917266845703\n",
      "Epoch 25, CIFAR-10 Batch 5:  Acc: 0.6309999227523804 Loss: 0.6822239756584167\n",
      "Epoch 26, CIFAR-10 Batch 1:  Acc: 0.6237998604774475 Loss: 0.7828385829925537\n",
      "Epoch 26, CIFAR-10 Batch 2:  Acc: 0.602199912071228 Loss: 0.6838778257369995\n",
      "Epoch 26, CIFAR-10 Batch 3:  Acc: 0.6291999220848083 Loss: 0.6022798418998718\n",
      "Epoch 26, CIFAR-10 Batch 4:  Acc: 0.6201999187469482 Loss: 0.6391708254814148\n",
      "Epoch 26, CIFAR-10 Batch 5:  Acc: 0.6215999126434326 Loss: 0.6570807099342346\n",
      "Epoch 27, CIFAR-10 Batch 1:  Acc: 0.6237998604774475 Loss: 0.7473893761634827\n",
      "Epoch 27, CIFAR-10 Batch 2:  Acc: 0.6131998896598816 Loss: 0.651966392993927\n",
      "Epoch 27, CIFAR-10 Batch 3:  Acc: 0.6275998950004578 Loss: 0.6136422157287598\n",
      "Epoch 27, CIFAR-10 Batch 4:  Acc: 0.6153998374938965 Loss: 0.6199619174003601\n",
      "Epoch 27, CIFAR-10 Batch 5:  Acc: 0.6289998888969421 Loss: 0.6357018947601318\n",
      "Epoch 28, CIFAR-10 Batch 1:  Acc: 0.6235998868942261 Loss: 0.7492701411247253\n",
      "Epoch 28, CIFAR-10 Batch 2:  Acc: 0.6167998909950256 Loss: 0.6396345496177673\n",
      "Epoch 28, CIFAR-10 Batch 3:  Acc: 0.6353998780250549 Loss: 0.6002185940742493\n",
      "Epoch 28, CIFAR-10 Batch 4:  Acc: 0.6269999146461487 Loss: 0.603901207447052\n",
      "Epoch 28, CIFAR-10 Batch 5:  Acc: 0.6327998638153076 Loss: 0.6344356536865234\n",
      "Epoch 29, CIFAR-10 Batch 1:  Acc: 0.6263998746871948 Loss: 0.7498077750205994\n",
      "Epoch 29, CIFAR-10 Batch 2:  Acc: 0.6053999066352844 Loss: 0.6638056039810181\n",
      "Epoch 29, CIFAR-10 Batch 3:  Acc: 0.6189998984336853 Loss: 0.6176465749740601\n",
      "Epoch 29, CIFAR-10 Batch 4:  Acc: 0.6275999546051025 Loss: 0.6110653281211853\n",
      "Epoch 29, CIFAR-10 Batch 5:  Acc: 0.6421998739242554 Loss: 0.6156758666038513\n",
      "Epoch 30, CIFAR-10 Batch 1:  Acc: 0.6285998821258545 Loss: 0.7253261208534241\n",
      "Epoch 30, CIFAR-10 Batch 2:  Acc: 0.6115999221801758 Loss: 0.6588510870933533\n",
      "Epoch 30, CIFAR-10 Batch 3:  Acc: 0.637799859046936 Loss: 0.5775813460350037\n",
      "Epoch 30, CIFAR-10 Batch 4:  Acc: 0.6289998292922974 Loss: 0.5818463563919067\n",
      "Epoch 30, CIFAR-10 Batch 5:  Acc: 0.6393999457359314 Loss: 0.5934213995933533\n",
      "Epoch 31, CIFAR-10 Batch 1:  Acc: 0.6329998970031738 Loss: 0.6781522035598755\n",
      "Epoch 31, CIFAR-10 Batch 2:  Acc: 0.6089998483657837 Loss: 0.6227377653121948\n",
      "Epoch 31, CIFAR-10 Batch 3:  Acc: 0.6333999037742615 Loss: 0.5686600208282471\n",
      "Epoch 31, CIFAR-10 Batch 4:  Acc: 0.6329998970031738 Loss: 0.5761604905128479\n",
      "Epoch 31, CIFAR-10 Batch 5:  Acc: 0.6335998773574829 Loss: 0.5946977734565735\n",
      "Epoch 32, CIFAR-10 Batch 1:  Acc: 0.6333999037742615 Loss: 0.6835489869117737\n",
      "Epoch 32, CIFAR-10 Batch 2:  Acc: 0.6219998598098755 Loss: 0.615888237953186\n",
      "Epoch 32, CIFAR-10 Batch 3:  Acc: 0.6373998522758484 Loss: 0.5739723443984985\n",
      "Epoch 32, CIFAR-10 Batch 4:  Acc: 0.6323999166488647 Loss: 0.5739156603813171\n",
      "Epoch 32, CIFAR-10 Batch 5:  Acc: 0.6379998326301575 Loss: 0.5720251202583313\n",
      "Epoch 33, CIFAR-10 Batch 1:  Acc: 0.6369999051094055 Loss: 0.6788733601570129\n",
      "Epoch 33, CIFAR-10 Batch 2:  Acc: 0.6243999600410461 Loss: 0.6105153560638428\n",
      "Epoch 33, CIFAR-10 Batch 3:  Acc: 0.6435999274253845 Loss: 0.5576465725898743\n",
      "Epoch 33, CIFAR-10 Batch 4:  Acc: 0.6319999098777771 Loss: 0.5795053839683533\n",
      "Epoch 33, CIFAR-10 Batch 5:  Acc: 0.6385999321937561 Loss: 0.5999098420143127\n",
      "Epoch 34, CIFAR-10 Batch 1:  Acc: 0.637799859046936 Loss: 0.6680290102958679\n",
      "Epoch 34, CIFAR-10 Batch 2:  Acc: 0.6217999458312988 Loss: 0.5874066948890686\n",
      "Epoch 34, CIFAR-10 Batch 3:  Acc: 0.6327999234199524 Loss: 0.5696147680282593\n",
      "Epoch 34, CIFAR-10 Batch 4:  Acc: 0.6365998983383179 Loss: 0.5580016374588013\n",
      "Epoch 34, CIFAR-10 Batch 5:  Acc: 0.63319993019104 Loss: 0.570671558380127\n",
      "Epoch 35, CIFAR-10 Batch 1:  Acc: 0.6369998455047607 Loss: 0.6305698156356812\n",
      "Epoch 35, CIFAR-10 Batch 2:  Acc: 0.625799834728241 Loss: 0.5750766396522522\n",
      "Epoch 35, CIFAR-10 Batch 3:  Acc: 0.6379998326301575 Loss: 0.5261097550392151\n",
      "Epoch 35, CIFAR-10 Batch 4:  Acc: 0.6357998847961426 Loss: 0.5399975180625916\n",
      "Epoch 35, CIFAR-10 Batch 5:  Acc: 0.6321999430656433 Loss: 0.5510468482971191\n",
      "Epoch 36, CIFAR-10 Batch 1:  Acc: 0.6345998644828796 Loss: 0.630085825920105\n",
      "Epoch 36, CIFAR-10 Batch 2:  Acc: 0.6359999179840088 Loss: 0.5373462438583374\n",
      "Epoch 36, CIFAR-10 Batch 3:  Acc: 0.6423998475074768 Loss: 0.5313862562179565\n",
      "Epoch 36, CIFAR-10 Batch 4:  Acc: 0.6285999417304993 Loss: 0.5410833954811096\n",
      "Epoch 36, CIFAR-10 Batch 5:  Acc: 0.6273999214172363 Loss: 0.541102409362793\n",
      "Epoch 37, CIFAR-10 Batch 1:  Acc: 0.6311998963356018 Loss: 0.5984025001525879\n",
      "Epoch 37, CIFAR-10 Batch 2:  Acc: 0.6263999342918396 Loss: 0.5421856045722961\n",
      "Epoch 37, CIFAR-10 Batch 3:  Acc: 0.6449999213218689 Loss: 0.5177216529846191\n",
      "Epoch 37, CIFAR-10 Batch 4:  Acc: 0.6281999349594116 Loss: 0.5518684983253479\n",
      "Epoch 37, CIFAR-10 Batch 5:  Acc: 0.6357999444007874 Loss: 0.5405473709106445\n",
      "Epoch 38, CIFAR-10 Batch 1:  Acc: 0.6337999105453491 Loss: 0.5895611643791199\n",
      "Epoch 38, CIFAR-10 Batch 2:  Acc: 0.6383998990058899 Loss: 0.5278182029724121\n",
      "Epoch 38, CIFAR-10 Batch 3:  Acc: 0.6325998902320862 Loss: 0.5082324147224426\n",
      "Epoch 38, CIFAR-10 Batch 4:  Acc: 0.6255999207496643 Loss: 0.5256531834602356\n",
      "Epoch 38, CIFAR-10 Batch 5:  Acc: 0.6337999105453491 Loss: 0.5225280523300171\n",
      "Epoch 39, CIFAR-10 Batch 1:  Acc: 0.6309998631477356 Loss: 0.5913881063461304\n",
      "Epoch 39, CIFAR-10 Batch 2:  Acc: 0.6365998983383179 Loss: 0.5303713083267212\n",
      "Epoch 39, CIFAR-10 Batch 3:  Acc: 0.6331998705863953 Loss: 0.5155973434448242\n",
      "Epoch 39, CIFAR-10 Batch 4:  Acc: 0.6353998780250549 Loss: 0.5068579912185669\n",
      "Epoch 39, CIFAR-10 Batch 5:  Acc: 0.63319993019104 Loss: 0.5439597964286804\n",
      "Epoch 40, CIFAR-10 Batch 1:  Acc: 0.6353998780250549 Loss: 0.6025592088699341\n",
      "Epoch 40, CIFAR-10 Batch 2:  Acc: 0.6395998597145081 Loss: 0.514366626739502\n",
      "Epoch 40, CIFAR-10 Batch 3:  Acc: 0.6363998651504517 Loss: 0.45724841952323914\n",
      "Epoch 40, CIFAR-10 Batch 4:  Acc: 0.6367999315261841 Loss: 0.4940372109413147\n",
      "Epoch 40, CIFAR-10 Batch 5:  Acc: 0.6385998725891113 Loss: 0.5086151957511902\n",
      "Epoch 41, CIFAR-10 Batch 1:  Acc: 0.6281999349594116 Loss: 0.5620176792144775\n",
      "Epoch 41, CIFAR-10 Batch 2:  Acc: 0.6379998922348022 Loss: 0.4777829051017761\n",
      "Epoch 41, CIFAR-10 Batch 3:  Acc: 0.6317998170852661 Loss: 0.48932772874832153\n",
      "Epoch 41, CIFAR-10 Batch 4:  Acc: 0.6409999132156372 Loss: 0.47762441635131836\n",
      "Epoch 41, CIFAR-10 Batch 5:  Acc: 0.6351999044418335 Loss: 0.496124267578125\n",
      "Epoch 42, CIFAR-10 Batch 1:  Acc: 0.6365998387336731 Loss: 0.5768064260482788\n",
      "Epoch 42, CIFAR-10 Batch 2:  Acc: 0.6363998651504517 Loss: 0.4738062024116516\n",
      "Epoch 42, CIFAR-10 Batch 3:  Acc: 0.6349998712539673 Loss: 0.46195337176322937\n",
      "Epoch 42, CIFAR-10 Batch 4:  Acc: 0.638999879360199 Loss: 0.4674912989139557\n",
      "Epoch 42, CIFAR-10 Batch 5:  Acc: 0.6313998699188232 Loss: 0.49487781524658203\n",
      "Epoch 43, CIFAR-10 Batch 1:  Acc: 0.6345999240875244 Loss: 0.5490888357162476\n",
      "Epoch 43, CIFAR-10 Batch 2:  Acc: 0.639799952507019 Loss: 0.48438769578933716\n",
      "Epoch 43, CIFAR-10 Batch 3:  Acc: 0.6319999694824219 Loss: 0.4855318069458008\n",
      "Epoch 43, CIFAR-10 Batch 4:  Acc: 0.6361998319625854 Loss: 0.4937967360019684\n",
      "Epoch 43, CIFAR-10 Batch 5:  Acc: 0.6235998868942261 Loss: 0.48774439096450806\n",
      "Epoch 44, CIFAR-10 Batch 1:  Acc: 0.6383999586105347 Loss: 0.5568996071815491\n",
      "Epoch 44, CIFAR-10 Batch 2:  Acc: 0.6343998908996582 Loss: 0.4612930417060852\n",
      "Epoch 44, CIFAR-10 Batch 3:  Acc: 0.6289999485015869 Loss: 0.4950222969055176\n",
      "Epoch 44, CIFAR-10 Batch 4:  Acc: 0.632599949836731 Loss: 0.4869251847267151\n",
      "Epoch 44, CIFAR-10 Batch 5:  Acc: 0.6315998435020447 Loss: 0.4553658664226532\n",
      "Epoch 45, CIFAR-10 Batch 1:  Acc: 0.6395999193191528 Loss: 0.5203150510787964\n",
      "Epoch 45, CIFAR-10 Batch 2:  Acc: 0.6377999186515808 Loss: 0.48358213901519775\n",
      "Epoch 45, CIFAR-10 Batch 3:  Acc: 0.6321998834609985 Loss: 0.4828166365623474\n",
      "Epoch 45, CIFAR-10 Batch 4:  Acc: 0.6373998522758484 Loss: 0.46234628558158875\n",
      "Epoch 45, CIFAR-10 Batch 5:  Acc: 0.6309998631477356 Loss: 0.45975735783576965\n",
      "Epoch 46, CIFAR-10 Batch 1:  Acc: 0.6311998963356018 Loss: 0.5415859818458557\n",
      "Epoch 46, CIFAR-10 Batch 2:  Acc: 0.6285998821258545 Loss: 0.49769026041030884\n",
      "Epoch 46, CIFAR-10 Batch 3:  Acc: 0.6319999098777771 Loss: 0.43629443645477295\n",
      "Epoch 46, CIFAR-10 Batch 4:  Acc: 0.6329998970031738 Loss: 0.46080106496810913\n",
      "Epoch 46, CIFAR-10 Batch 5:  Acc: 0.6315998435020447 Loss: 0.45504915714263916\n",
      "Epoch 47, CIFAR-10 Batch 1:  Acc: 0.6327998638153076 Loss: 0.5376572608947754\n",
      "Epoch 47, CIFAR-10 Batch 2:  Acc: 0.6435998678207397 Loss: 0.48667919635772705\n",
      "Epoch 47, CIFAR-10 Batch 3:  Acc: 0.6351999044418335 Loss: 0.438440203666687\n",
      "Epoch 47, CIFAR-10 Batch 4:  Acc: 0.6369999051094055 Loss: 0.42063915729522705\n",
      "Epoch 47, CIFAR-10 Batch 5:  Acc: 0.630599856376648 Loss: 0.48260951042175293\n",
      "Epoch 48, CIFAR-10 Batch 1:  Acc: 0.63319993019104 Loss: 0.5146256685256958\n",
      "Epoch 48, CIFAR-10 Batch 2:  Acc: 0.6369999647140503 Loss: 0.5014367699623108\n",
      "Epoch 48, CIFAR-10 Batch 3:  Acc: 0.6325998902320862 Loss: 0.4335886538028717\n",
      "Epoch 48, CIFAR-10 Batch 4:  Acc: 0.6397998929023743 Loss: 0.4559885263442993\n",
      "Epoch 48, CIFAR-10 Batch 5:  Acc: 0.6281998753547668 Loss: 0.4534803330898285\n",
      "Epoch 49, CIFAR-10 Batch 1:  Acc: 0.6297998428344727 Loss: 0.49747276306152344\n",
      "Epoch 49, CIFAR-10 Batch 2:  Acc: 0.6287998557090759 Loss: 0.4702129364013672\n",
      "Epoch 49, CIFAR-10 Batch 3:  Acc: 0.636199951171875 Loss: 0.42810314893722534\n",
      "Epoch 49, CIFAR-10 Batch 4:  Acc: 0.6339999437332153 Loss: 0.4297458529472351\n",
      "Epoch 49, CIFAR-10 Batch 5:  Acc: 0.627799928188324 Loss: 0.4218025207519531\n",
      "Epoch 50, CIFAR-10 Batch 1:  Acc: 0.6317999362945557 Loss: 0.48885196447372437\n",
      "Epoch 50, CIFAR-10 Batch 2:  Acc: 0.6317999362945557 Loss: 0.43115317821502686\n",
      "Epoch 50, CIFAR-10 Batch 3:  Acc: 0.6307999491691589 Loss: 0.41904085874557495\n",
      "Epoch 50, CIFAR-10 Batch 4:  Acc: 0.6339999437332153 Loss: 0.4231746196746826\n",
      "Epoch 50, CIFAR-10 Batch 5:  Acc: 0.6299998760223389 Loss: 0.43371400237083435\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6317555159330368\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREREYn+PxxT5Zrt9m2fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bb892cfa58>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
